{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import  train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "##There might be a better way! \n",
    "\n",
    "folders = [1,2,3,4,5,6,7,8,9,0]\n",
    "images = []\n",
    "labels = []\n",
    "import os\n",
    "for f in folders: \n",
    "    os.chdir(('/Users/vgulbi/Desktop/Hackathon/programmerhumor-hackathon/public/pyscripts/Data/NumDB/{}').format(f))\n",
    "    for file in glob.glob(\"*.jpg\"):\n",
    "        im = cv2.imread(file,0)\n",
    "        im = (255-im)\n",
    "        im = cv2.resize(im,(8,8))  \n",
    "        images.append(im)\n",
    "        labels.append(f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "myarray = np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCdTANOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a247fb780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "##creating a list of arrays that contain image pixel values and their labels\n",
    "images_and_labels = list(zip(images, labels))\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get images only\n",
    "n_samples = len(myarray)\n",
    "data = myarray.reshape((n_samples, -1))\n",
    "\n",
    "## Training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/vgulbi/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.064907</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 20}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006136</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.149367</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 50}</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.454024</td>\n",
       "      <td>0.016873</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 150}</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070436</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 20}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.328276</td>\n",
       "      <td>0.012271</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016061</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.170996</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.644146</td>\n",
       "      <td>0.022041</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 200}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.476261</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 150}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.337597</td>\n",
       "      <td>0.011262</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.218796</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.097321</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.760231</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 200}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.190012</td>\n",
       "      <td>0.021033</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.487983</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 150}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.478847</td>\n",
       "      <td>0.027421</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 150}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035880</td>\n",
       "      <td>0.020224</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.316507</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.177879</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 50}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028515</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067322</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 20}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.639256</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 200}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034004</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302398</td>\n",
       "      <td>0.010336</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'n_estimators': 100}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016424</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.613289</td>\n",
       "      <td>0.020259</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 200}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084006</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.112134</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.996283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024486</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "15       0.064907         0.002672         1.000000               1.0   \n",
       "1        0.149367         0.006689         0.998761               1.0   \n",
       "3        0.454024         0.016873         0.998761               1.0   \n",
       "0        0.070436         0.003987         0.997522               1.0   \n",
       "17       0.328276         0.012271         0.997522               1.0   \n",
       "16       0.170996         0.006284         0.997522               1.0   \n",
       "14       0.644146         0.022041         0.997522               1.0   \n",
       "13       0.476261         0.016317         0.997522               1.0   \n",
       "12       0.337597         0.011262         0.997522               1.0   \n",
       "11       0.218796         0.007587         0.997522               1.0   \n",
       "9        0.760231         0.032005         0.997522               1.0   \n",
       "18       0.487983         0.016901         0.997522               1.0   \n",
       "8        0.478847         0.027421         0.997522               1.0   \n",
       "7        0.316507         0.011019         0.997522               1.0   \n",
       "6        0.177879         0.009641         0.997522               1.0   \n",
       "5        0.067322         0.002504         0.997522               1.0   \n",
       "4        0.639256         0.021644         0.997522               1.0   \n",
       "2        0.302398         0.010336         0.997522               1.0   \n",
       "19       0.613289         0.020259         0.997522               1.0   \n",
       "10       0.112134         0.004912         0.996283               1.0   \n",
       "\n",
       "   param_max_depth param_n_estimators                                  params  \\\n",
       "15              15                 20   {'max_depth': 15, 'n_estimators': 20}   \n",
       "1                6                 50    {'max_depth': 6, 'n_estimators': 50}   \n",
       "3                6                150   {'max_depth': 6, 'n_estimators': 150}   \n",
       "0                6                 20    {'max_depth': 6, 'n_estimators': 20}   \n",
       "17              15                100  {'max_depth': 15, 'n_estimators': 100}   \n",
       "16              15                 50   {'max_depth': 15, 'n_estimators': 50}   \n",
       "14              10                200  {'max_depth': 10, 'n_estimators': 200}   \n",
       "13              10                150  {'max_depth': 10, 'n_estimators': 150}   \n",
       "12              10                100  {'max_depth': 10, 'n_estimators': 100}   \n",
       "11              10                 50   {'max_depth': 10, 'n_estimators': 50}   \n",
       "9                8                200   {'max_depth': 8, 'n_estimators': 200}   \n",
       "18              15                150  {'max_depth': 15, 'n_estimators': 150}   \n",
       "8                8                150   {'max_depth': 8, 'n_estimators': 150}   \n",
       "7                8                100   {'max_depth': 8, 'n_estimators': 100}   \n",
       "6                8                 50    {'max_depth': 8, 'n_estimators': 50}   \n",
       "5                8                 20    {'max_depth': 8, 'n_estimators': 20}   \n",
       "4                6                200   {'max_depth': 6, 'n_estimators': 200}   \n",
       "2                6                100   {'max_depth': 6, 'n_estimators': 100}   \n",
       "19              15                200  {'max_depth': 15, 'n_estimators': 200}   \n",
       "10              10                 20   {'max_depth': 10, 'n_estimators': 20}   \n",
       "\n",
       "    rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
       "15                1                1.0                 1.0       ...          \n",
       "1                 2                1.0                 1.0       ...          \n",
       "3                 2                1.0                 1.0       ...          \n",
       "0                 4                1.0                 1.0       ...          \n",
       "17                4                1.0                 1.0       ...          \n",
       "16                4                1.0                 1.0       ...          \n",
       "14                4                1.0                 1.0       ...          \n",
       "13                4                1.0                 1.0       ...          \n",
       "12                4                1.0                 1.0       ...          \n",
       "11                4                1.0                 1.0       ...          \n",
       "9                 4                1.0                 1.0       ...          \n",
       "18                4                1.0                 1.0       ...          \n",
       "8                 4                1.0                 1.0       ...          \n",
       "7                 4                1.0                 1.0       ...          \n",
       "6                 4                1.0                 1.0       ...          \n",
       "5                 4                1.0                 1.0       ...          \n",
       "4                 4                1.0                 1.0       ...          \n",
       "2                 4                1.0                 1.0       ...          \n",
       "19                4                1.0                 1.0       ...          \n",
       "10               20                1.0                 1.0       ...          \n",
       "\n",
       "    split7_test_score  split7_train_score  split8_test_score  \\\n",
       "15                1.0                 1.0                1.0   \n",
       "1                 1.0                 1.0                1.0   \n",
       "3                 1.0                 1.0                1.0   \n",
       "0                 1.0                 1.0                1.0   \n",
       "17                1.0                 1.0                1.0   \n",
       "16                1.0                 1.0                1.0   \n",
       "14                1.0                 1.0                1.0   \n",
       "13                1.0                 1.0                1.0   \n",
       "12                1.0                 1.0                1.0   \n",
       "11                1.0                 1.0                1.0   \n",
       "9                 1.0                 1.0                1.0   \n",
       "18                1.0                 1.0                1.0   \n",
       "8                 1.0                 1.0                1.0   \n",
       "7                 1.0                 1.0                1.0   \n",
       "6                 1.0                 1.0                1.0   \n",
       "5                 1.0                 1.0                1.0   \n",
       "4                 1.0                 1.0                1.0   \n",
       "2                 1.0                 1.0                1.0   \n",
       "19                1.0                 1.0                1.0   \n",
       "10                1.0                 1.0                1.0   \n",
       "\n",
       "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "15                 1.0                1.0                 1.0      0.006136   \n",
       "1                  1.0                1.0                 1.0      0.006457   \n",
       "3                  1.0                1.0                 1.0      0.013330   \n",
       "0                  1.0                1.0                 1.0      0.007857   \n",
       "17                 1.0                1.0                 1.0      0.016061   \n",
       "16                 1.0                1.0                 1.0      0.008747   \n",
       "14                 1.0                1.0                 1.0      0.022083   \n",
       "13                 1.0                1.0                 1.0      0.016222   \n",
       "12                 1.0                1.0                 1.0      0.007857   \n",
       "11                 1.0                1.0                 1.0      0.097321   \n",
       "9                  1.0                1.0                 1.0      0.190012   \n",
       "18                 1.0                1.0                 1.0      0.013631   \n",
       "8                  1.0                1.0                 1.0      0.035880   \n",
       "7                  1.0                1.0                 1.0      0.027078   \n",
       "6                  1.0                1.0                 1.0      0.028515   \n",
       "5                  1.0                1.0                 1.0      0.009418   \n",
       "4                  1.0                1.0                 1.0      0.034004   \n",
       "2                  1.0                1.0                 1.0      0.016424   \n",
       "19                 1.0                1.0                 1.0      0.084006   \n",
       "10                 1.0                1.0                 1.0      0.024486   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "15        0.000066        0.000000              0.0  \n",
       "1         0.002962        0.003710              0.0  \n",
       "3         0.003534        0.003710              0.0  \n",
       "0         0.001349        0.007420              0.0  \n",
       "17        0.004685        0.007420              0.0  \n",
       "16        0.000951        0.007420              0.0  \n",
       "14        0.002013        0.007420              0.0  \n",
       "13        0.001834        0.007420              0.0  \n",
       "12        0.000646        0.007420              0.0  \n",
       "11        0.002911        0.007420              0.0  \n",
       "9         0.021033        0.007420              0.0  \n",
       "18        0.001996        0.007420              0.0  \n",
       "8         0.020224        0.007420              0.0  \n",
       "7         0.001512        0.007420              0.0  \n",
       "6         0.004982        0.007420              0.0  \n",
       "5         0.000263        0.007420              0.0  \n",
       "4         0.003403        0.007420              0.0  \n",
       "2         0.000593        0.007420              0.0  \n",
       "19        0.003416        0.007420              0.0  \n",
       "10        0.002072        0.007941              0.0  \n",
       "\n",
       "[20 rows x 32 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Tune hyperparameters\n",
    "clf = GridSearchCV(cv=10,estimator = RandomForestClassifier(), param_grid={'n_estimators':[20,50,100,150,200, ], 'max_depth':[6,8,10,15]},n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "pd.DataFrame(clf.cv_results_).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators = 20, max_depth = 15)\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        24\n",
      "          1       1.00      1.00      1.00        17\n",
      "          2       1.00      1.00      1.00        10\n",
      "          3       1.00      1.00      1.00        25\n",
      "          4       1.00      1.00      1.00        26\n",
      "          5       1.00      1.00      1.00        21\n",
      "          6       1.00      1.00      1.00        19\n",
      "          7       1.00      1.00      1.00        13\n",
      "          8       1.00      1.00      1.00        27\n",
      "          9       1.00      1.00      1.00        20\n",
      "\n",
      "avg / total       1.00      1.00      1.00       202\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[24  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 26  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 21  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 19  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 13  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 27  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's see how it performs on the unseen Data\n",
    "expected = y_test\n",
    "predicted = RF.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (RF, classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ..., 255 255 255]\n",
      " [255 255 255 ..., 255 255 255]\n",
      " [255 255 255 ..., 255 255 255]\n",
      " ..., \n",
      " [255 255 255 ..., 255 255 255]\n",
      " [255 255 255 ..., 255 255 255]\n",
      " [255 255 255 ..., 255 255 255]]\n",
      "[8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANkAAAD8CAYAAAD63wHzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHEJJREFUeJztnX+QXNV15z/n9ev5ETAakBEWSGsB\nkk1cLn4ZCJgI+cdCkNcOogoqmNgIm5T+cIjJQlmBDb/WEq54aw2O7DW1kpFLtqiYLNgLlndjU/pl\nXGUIAozAKARZYCEDEgJJYEYz093v5I9+t9USM5qe7n73vu45n6queX37TZ8zb9733XPvPfdeUVUM\nw8iOKLQDhtHtmMgMI2NMZIaRMSYyw8gYE5lhZIyJzDAyxrvIRORiEXleRLaKyI2+7RuGb8TnOJmI\nFIB/By4EdgCPA59V1ee8OWEYnvFdk50DbFXVbao6AvwQuMSzD4bhldizvROAl+ve7wD+pP4EEVkE\nLErffsSTX4bRDLtV9djxTvItMhml7KB4VVWXA8sBRMRyvow887tGTvIdLu4AZta9nwG84tkHw/CK\nb5E9DswRkRNFpAe4AnjIsw+G4RWv4aKqlkXkWuBnQAFYqaq/8emDYfjGaxf+RLE2mZFznlDVs8Y7\nyTI+DCNjTGSGkTEmMsPIGBOZYWSMicwwMsZEZhgZYyIzjIwxkRlGxpjIDCNjTGSGkTEmMsPIGBOZ\nYWSMicwwMsZEZhgZYyIzjIwxkRlGxpjIDCNjTGSGkTEmMsPIGBOZYWSMicwwMsZEZhgZYyIzjIwx\nkRlGxpjIDCNjTGQdjoiMeuyIY98b9xiHYv+BDmHu3Ln8/Oc/p1gs0u6l1ZMkQUSYNm0ae/fubet3\nGyayXBJFEX/4wx/o6ekBQFVRVUSESqVCFLU3AEmShDiO2bVrF1CtEUWEp556irPPPruttiYjFi7m\ngCiKuPnmm6lUKpRKJYaHh2s1lqu1XCjYboHBgZDSiQuqwj799NMplUq1l7NvIejEMJEF5rvf/S7l\ncplbbrmFJElCuzMmqsrIyAjDw8Ncfvnlod3pKGzrpECMjIzUaqU8/w9GI4oikiRh/fr1XHTRRaHd\nCUlDWyeZyDxTqVRyXWNNlCiKKJVK9Pf319qNeb6n2oztT5YnPv7xjzMyMtJVAoMDPZPlchnovFrZ\nB9aCzRDXiTAyMhLYk2xx4WOpVKJSqdDX1xfapVzRdE0mIjNFZL2IbBGR34jIdWn5MSLysIi8kP48\nOi0XEVkmIltFZLOInNmuPyKvfP7zn2d4eHjUQeJupttq61ZpJVwsAzeo6h8D5wJ/LSIfAm4E1qrq\nHGBt+h5gPjAnfS0C7m7Bdq6JoohLL72Uu+++e7K1USgUCqgqQ0NDQDZDDp1G01dAVV9V1SfT47eB\nLcAJwCXAqvS0VcCC9PgS4Pta5VFgQESmN+15jnn00Ue57777Jm3YpKoUi0VKpRJXXnllaHeC05bH\njIjMAs4AHgOOU9VXoSpEYFp62gnAy3W/tiMtO/S7FonIJhHZ1A7ffJMkCaeeeiqqOmnDJve3J0nC\nihUruOeee0K7FJSWRSYiRwIPAH+rqm8d7tRRyt4VR6nqclU9q5Gu0TzhMjSSJKFQKFiYxIHskCuv\nvJLh4eHQ7gSjpTtBRIpUBXavqv4oLd7pwsD05660fAcws+7XZwCvtGI/T3znO9+hUqlMqvZXo7h2\n2oc//OHQrgShld5FAe4BtqjqnXUfPQQsTI8XAg/WlV+V9jKeC+xzYWWn8/jjj3PVVVeZwMZARCgU\nCjz99NOIyKTLfWw640NE/hR4BHgGcI2P/0a1XfbPwH8CtgOXq+qbqSi/DVwMDAJfUNXDtrs6JeOj\n27I4ssJdo97e3sCetA1Lq8oSN/aVJEkt28EYHxc6FgqF0K60A0uryhJVZXh42AQ2QVytv27dutCu\neMNE1gKVSiW0Cx3LeeedF9oFb5jImiCOY+vkaJE4jrs+p9Mxubp52sSXvvQlRkZGJl0vWTupn4Xd\n7VjHRxO4qfhG66hqbS2TDsQ6PrJgwYIF45/kATe9xCUg17/cgjuHnltPXnr3RIQpU6aEdiNTrCab\nIMPDw7noglZVoihCVfnKV77CsmXLakIqFouUy+V3tRudIEdGRnITqjmfisViaFeaoaGazBoVEyRk\nTmIcx7UaasmSJXzta18bdQhhrHDWic6FZ3EcMzQ0RBRFwXpK61fk6lYsXJwATz75ZFD7qsqSJUuI\n45ivfvWrLWeZlMtl4jhm3rx5QR8eIsI3vvGNYPazxsLFCTA8PBzkZnQh1Qc+8AFefPHFzOyE6tBx\na4R04Pw7CxfbTbFYDBJWRVHkRdxuoqVvXPsS6MqZ5BYuNsjWrVuDCMx3J0uxWAwy/le/cnG3YSJr\nkFmzZnm157rnzznnHO83Xn3ys09+/OMf56bXs52YyBrE943uZlf/+te/9mrXhW1Lly713q0+f/58\nr/Z8YR0fDeJ7bCmKouBjcaONtWWJiNDX19dJMxss46Od+H4YhX74iQirV6/2arNbFx+ymqwBpkyZ\nws6dO713QITEhY0uU97HfdKBeYxWk7WLO++8c/yT2kSSJMFrMedHfW6kDwqFArfeeqsXWz4xkTXA\n5z73OW+1WBRF3HHHHV5sNcKyZcu82UqShOuvv96bPV9YuNgAvjs9QoeK9YiIt8mVIuJt4L1NWLjY\nLnw+iPL20HNTZ3xQLpe7ckkHE1kDdNCTte242sUHhULBBqON7MljTWYzwVvDRJYz8lhr+ur06dZ1\nPywLvwF8Jq/mrSbziap2UrZHw+TvsZlDNmzY4LVBnrenuc/adePGjd5s+cJE1gBLly71dqPlcTq+\nr1SnJEn48pe/7MWWT2ycrAFEhFKpNGlTi3yOE/b29nZS/qKNk7UTXzdZ/SzhyYaIdJLAGmZy/jcn\niM8GeRzHzJ0714utRli5cqU3W3mOqlrBwsUG8RUyuad5XkLGUqnkLUn4pz/9aW4Wj20QCxfbyWWX\nXebFjktjykP+ohNX1iGce3h1mMAaxkTWID/5yU+82vv2t7/t1d5ovP/97/fSPuzGsbF6Wg4XRaQA\nbAJ+r6qfFpETgR8CxwBPAp9X1RER6QW+D3wEeAP4C1V9aZzvzk24CP7XXQxZm4kIw8PDXkLkJEko\nFAqduEuOt3DxOmBL3fuvA3ep6hxgD3BNWn4NsEdVZwN3ped1FD73OlZVvve97wUbmJ45c6a3B0q3\nb9beUk0mIjOAVcAdwPXAZ4DXgfepallEzgNuV9U/E5Gfpce/EpEYeA04Vg/jQN5qMvC3yq4TV09P\nT5Bu7VKpNOpuMFngVubqQLzUZN8EFgPuPzEV2KuqLsjeAZyQHp8AvAyQfr4vPf8gRGSRiGwSkU0t\n+pYJ27Zt8/LUdZkfQ0NDmdtyuBrFPfd8iXvbtm1e7ISiaZGJyKeBXar6RH3xKKdqA58dKFBdrqpn\nNfKECMEHP/hBr9uw+txxRVUZHBz02hERxzGzZ8/OXb5mO2mlJjsf+HMReYlqR8cnqNZsA2k4CDAD\neCU93gHMBEg/nwK82YL9YDz66KPebLkazYfQBgcHvd/s3bw8t6NpkanqTao6Q1VnAVcA61T1L4H1\ngBtUWgg8mB4/lL4n/Xzd4dpjeWbevHnebSZJkmkNMzw8nIuxuW4ki9bm3wHXi8hWqm2ue9Lye4Cp\nafn1wI0Z2PZGb2+v13xGqAptZGSkLWJzHQ2VSiXIllAikpuslqxpy5VV1Q2q+un0eJuqnqOqs1X1\nclUdTsuH0vez0887urXrxnZ89vy5mcMulzJJEubPn3+QQKIoGlf8K1euZGhoiFKpRJIkXgVWqVQQ\nEZ5++umuDhHrsdzFFgm1/3J9W8btHa2qrFu3jjvvvJPBwcGaeG699VY+9rGP1c4Pme3egcu+HY6G\nuvBNZG3AZxJtJ+N6SrsoTLQEYV8cd9xxJrAGKJfL3SSwhjGRtYE333yTs88+G/C/cV4n4ELa6dOn\nh3YlCBYutpGBgQF2796NiNQa+JMd11kzdepU9u7dG9qddmMbs/tm7969xHFMpVLxurx1nnGpWpP5\nWli4mAFu2sZkvbHqs1MKhULXbu7XKCayDIiiiDiOczHxMgRuTXvLIKlibTIPlMvl2hO9G3ctgWrt\n5abG9PX1TZYhDevCzwsudHRttW5BVWtZL1EUMWfOHPr6+mqfGVWs48MjLnxytVmnt1NcW+vll19m\n9uzZ3ZLF0XbsqgSgUCiwatWq0G60TE9PD319fcyZMwfI5440ecBqMo9EUcTu3bs58sgjO74WgwOT\nPFWViy++mPXr14d2KZfYo8cTCxcu5J133uE973kPIuJtz68scQPuURSxdu3agzp1JuvwxWhYTZYx\nc+fOZePGjV2795bDCa5cLndTln1bMJFlRBRFDA8PAwc6Orr9xnM9im6D9SRJbKwMCxczwS0MOlmp\nn69m+02byNpOqVRiZGTExonqqFQqvP7666HdCIaJrE1EUcTIyEjtCW4N/wMkScLAwADlcnlSXhcT\nWZsYGhqq9bQZo1Mul3nnnXdCu+EduyPawODgYGgXOgKXODzZajQTWZO4m2RwcJBisTipbppWcMuA\n+1yFOTQmsibxvU59t6Gqk6bn0UTWJLt376ZQKAQfB6qvQZMkOahd6Kb+u7UYC4VCLWs+dM3r7Hfr\n1J96TGQTJIoiXnjhBaZOnZqLG0RE+MxnPkOxWKS3t5eenp6a+OM4Jo5jisUixWKxtkWRaxflAdcr\nG1r0WWKTNpsgZIqUmwz53ve+l3379rU0OdLNcUuSJPi43sknn8z27duD+tAENmkzC9zy2KFYs2YN\n/f397Nu3D2h+cqRbdTiKImbNmtVGD5tj69atoV3IDMtdnAAnnXRSbTnsELSz/Vf/oNi5cyc9PT1s\n2rSJU089tW02JoKI8NprrzF9+vTgtWq7sXCxQUSE/fv3e5+iUiqV6O3t9Wp3//79QfZwVlWOPfbY\nWi3dAVi42E5C5SO6Dguf9Pf3e7VXz86dO7sua6a7/pqMcFnlPp/ubnOGUEMEIQbY3TBDnqOrZjCR\nNUCIDPJyuVxb+SkEURRx5plnBrHdbdOETGQNMDAw4D2ECT2OlSQJmzdvDlKzWE02CQlxkx1xxBFe\nbY6FG7z2OWzhBqi7hZZEJiIDInK/iPybiGwRkfNE5BgReVhEXkh/Hp2eKyKyTES2ishmEQkTi0yQ\n/fv3e7UnIrUl1vJCiHZhN2WAtFqT/SPwL6p6CnAasIXqhutrVXUOsJYDG7DPB+akr0XA3S3a9oLv\nGyxJEn73u995tdkIvm/6bgoZmxaZiBwFXADcA6CqI6q6F7gEcCt3rgIWpMeXAN/XKo8CAyKS613h\nfvvb33pvGz344INe7TXKHXfc4dVeHMddEzI2PRgtIqcDy4HnqNZiTwDXAb9X1YG68/ao6tEisgb4\nB1X9ZVq+Fvg7Vd10yPcuolrTAXykKefagBt8dvOfskZVcz0vTUS83/RRFOV9fcrMB6Nj4EzgblU9\nA3iHA6HhaIx297zr7lXV5ap6ViPOZ4nbTMFX2OK7c2GiuOvgM4zL8/WYCK2IbAewQ1UfS9/fT1V0\nO10YmP7cVXf+zLrfnwG80oL9rqJSqXDDDTeEduOwrF692rvNBx54wLvNdtNS7qKIPAL8lao+LyK3\nA67f+Q1V/QcRuRE4RlUXi8h/Aa4FPgX8CbBMVc8Z5/uDtX53797NlClTvNoMPQG0EYaHh72OGbo5\ncDnFy57RfwPcKyI9wDbgC1Rrx38WkWuA7cDl6bn/j6rAtgKD6bm55cgjj/Rqz007yXuIFMexVx9D\nD8q3A8vCH4Nyuey1/bF9+3ZOPvlkb/aaIY5jBgcHvXfO5LiGtyz8VvAdonzxi1/Mc1gEVNuNW7Zs\n8Woz7zV7I+T7vxoQn2GKqrJx48bc31CqyuLFi73adFvldjIWLo6BW/vCB6pKT0+PF1ut4NYT8bmU\nm9tvO6dYuNgp5PgmOghV9e5rN3R8mMhG4YILLvAauuU5mjiUEL7OmzfPu812YiIbhU7/pxr5wkQ2\nCp0SvoWg0zshQmBXLAfkPAn2IEL0gHa6sDvb+y6hkxr3N910k3ebzzzzjHeb7cRENgp79uzxai+K\nIm6//XavNpvl2muv9WovSRJ2797t1Wa7MZGNwrPPPuvd5s033+zd5kQREY4//nivNvM+QN8INhg9\nBiH2zspxjh5AbTcYnze+iNDT05NXsdlgdCuEWNgz76iq95s95N4D7cJENga+e7TysDFfHsnDtk6t\nYiIbgxCr2OZ9e9xKpWI1fBOYyHJC/Ta0eSVE7mI3rFhl+5ONQYgB4jw/tV0Gvu/QLcQWTu0m34/O\nSYRbDjuvT+5QO2GecsopQey2ExPZGMyePdurvSRJao38PHblh9jyVkR46aWXvNttNyayMQi1SXiS\nJLz11ltAfsLH2267jUql4tWmqnq3mRU2GH0YQgxIiwilUon+/v5aOyg0bgDat+ife+45TjvtNK82\nJ0hDg9EmssPg2kchahRVpbe3N6jIoihi//79iIj3a9ABS3SDZXy0zrRp04KFbHlYg3HFihXB/Mjz\nw3+imMgOw969e4O1C1SVcrnMihUrgtgHuPrqq4EwwxkhxuSywkQ2Dm+//XZQ+1dffTULFy70dsO5\n0LBUKgWrSV0Pa7fUZiaycTj22GNDu8DKlSsplUqZLxsnIsydOzf4JNJuEZfDRNYAIRr+9bjxs6xr\n1QULFrB27drgbcG8p5dNlO76azJi9uzZuWgfqCojIyOsW7eurd/rMk3uv//+tn5vs3TCQq8TwUTW\nAC+99FLwEAqqHRAupCuVSmzYsKH2WbMPgUqlUuvcCV2DVSoVrxsv+sJE1iB5aJsdyvnnn0+pVKJU\nKtWm5oyXUHvLLbdQLpdrv5ckSZApLKPRCTMRmqHzU5w98dZbbxHHcS5qtLEYGRmp1QSHZovUb5eb\nl0ySQ/nVr34V2oVMsIyPCVIqlXJ7k3YqTvxHHHFELVG6Q7CMj3YTxzEPPfRQLkKrbiKKInp7eymX\ny7mcgdAqLYlMRP6riPxGRJ4VkX8SkT4ROVFEHhORF0TkvnSrW0SkN32/Nf18Vjv+AJ+Uy2Uuu+wy\nE1kbcTmKri0ZYtmHrGlaZCJyAvBl4CxV/TBQAK4Avg7cpapzgD3ANemvXAPsUdXZwF3peR2H29vZ\naB9RFOW6rdsqrd4tMdAvIjHwR8CrwCcAN+CyCliQHl+Svif9/JPSgVWCE1g3pf2EpBuWFxiPpkWm\nqr8H/iewnaq49gFPAHtV1T2WdgAnpMcnAC+nv1tOz5966PeKyCIR2SQim5r1LUvqG+XdOKbjC1Vl\n8+bNk+L6tRIuHk21djoROB44Apg/yqnuKo5Wa73rCqvqclU9q5Fem9AUCoVO6gnLFarKWWfl/l/c\nFloJF/8z8KKqvq6qJeBHwEeBgTR8BJgBvJIe7wBmAqSfTwHebMF+Lujr6wPCZ0t0Cq6jo6+vb1LU\nYtCayLYD54rIH6Vtq08CzwHrgcvScxYCD6bHD6XvST9fp11ylXt6erq64d5OyuVyrV3bgU3ypmhp\nMFpE/jvwF0AZeAr4K6ptrx8Cx6Rln1PVYRHpA34AnEG1BrtCVbeN8/0dI0IRYWhoyAR3GOI4Joqi\nbqrBbI2PEOzatYujjjqqE9an8IZbhKfbsuuxjI8wTJs2jb6+vkkTCjXCsmXL6O3tDe1GMExkGdHX\n10eSJMRxPCkFJyIUCgV+8IMfsHjx4kl5DRzdPxIYiEqlQm9vL0NDQ5Nu4NotTOp6Xl3ZZMVqsoxw\nN1VfX18tN28ypGOVy2WeeeaZgwQ22bGazBNRFDE0NNT1Qjv++OPZs2ePTQeqo7v/4znCrQjspnJ0\nSxtFVSkUClx44YX09/ezZ8+eWrlRxUQWgGKxWEuMFRHiOO6om9L5XigUWLJkCXEcs2HDBhsfHAMT\nWUCc2J5//vmOCyPvvfdeoihi6dKlllI2DjYYnRNcG6Z+5d48CM/NNFBV3njjDd73vvcBFg6m2GB0\nJ+Fu2mKxSG9vL319fVx66aXBa4mFCxfWekePO+4469BoAhNZTlFV1qxZQ39/P8Visfb61re+RaFQ\nIIqiWttIVZsSoxOL+91f/vKXNTs9PT0Ui0VWr1590O+EFn0nYuFiF3Hbbbfx0Y9+lNNOO42BgYGD\n8ieTJGHjxo088sgjbNy4kV/84hcBPe0aLEF4MjFeGGdhXiZYm2wyMZ6ATGDhMJEZRsaYyAwjY0xk\nhpExJjLDyBgTmWFkjInMMDLGRGYYGWMiM4yMMZEZRsaYyAwjY0xkhpExJjLDyBgTmWFkjInMMDLG\nRGYYGWMiM4yMMZEZRsaYyAwjY0xkhpExJjLDyJhxRSYiK0Vkl4g8W1d2jIg8LCIvpD+PTstFRJaJ\nyFYR2SwiZ9b9zsL0/BdEZOFotgyjK3FLMI/1Ai4AzgSerSv7H8CN6fGNwNfT408B/x8Q4FzgsbT8\nGGBb+vPo9PjoBmyrveyV49em8e5hVR2/JlPVXwBvHlJ8CbAqPV4FLKgr/75WeRQYEJHpwJ8BD6vq\nm6q6B3gYuHg824bRDTS7CeBxqvoqgKq+KiLT0vITgJfrztuRlo1V/i5EZBGwqEm/DCN3tHunzdF2\nttPDlL+7UHU5sBxsBWGjO2i2d3FnGgaS/tyVlu8AZtadNwN45TDlhtH1NCuyh4CF6fFC4MG68qvS\nXsZzgX1pWPkz4CIROTrtibwoLTOM7qeBHr5/Al4FSlRrpGuAqcBa4IX05zHpuQL8L+C3wDPAWXXf\n80Vga/r6QiO9MoTvPbKXvQ73aqh3Me+7urwNPB/ajwZ5L7A7tBMN0Cl+Qv59fb+qHjveSe3u+Gg3\nzzeyNU0eEJFNneBrp/gJneXr4bC0KsPIGBOZYWRM3kW2PLQDE6BTfO0UP6GzfB2TXHd8GEY3kPea\nzDA6HhOZYWRMbkUmIheLyPPp3LQbA/syU0TWi8gWEfmNiFyXlk94Xp0nfwsi8pSIrEnfnygij6V+\n3iciPWl5b/p+a/r5LM9+DojI/SLyb+m1PS+v17QVcikyESlQzRyZD3wI+KyIfCigS2XgBlX9Y6rz\n5P469edGYK2qzqGa+eIeBvOBOelrEXC3Z3+vA7bUvf86cFfq5x6qWTukP/eo6mzgrvQ8n/wj8C+q\negpwGlWf83pNm6eRtBDfL+A84Gd1728CbgrtV50/DwIXUs1GmZ6WTac6eA7wv4HP1p1fO8+DbzOo\n3pyfANZQTXXbDcSHXluq+aPnpcdxep548vMo4MVD7eXxmrb6ymVNxgTmn/kmDanOAB7jkHl1wHjz\n6nzwTWAxkKTvpwJ7VbU8ii81P9PP96Xn++Ak4HXge2lo+10ROYJ8XtOWyKvIGp5/5hMRORJ4APhb\nVX3rcKeOUpa5/yLyaWCXqj7RoC8hr3NMdVmLu1X1DOAdDoSGo5HLe6IR8iqy3M0/E5EiVYHdq6o/\nSosnOq8ua84H/lxEXgJ+SDVk/CbVZSBcnmq9LzU/08+n8O6lJrJiB7BDVR9L399PVXR5u6Ytk1eR\nPQ7MSXvFeoArqM5VC4KICHAPsEVV76z7aKLz6jJFVW9S1RmqOovqNVunqn8JrAcuG8NP5/9l6fle\nagdVfQ14WUQ+mBZ9EniOnF3TthC6UXiYhvGngH+nOjft7wP78qdUQ5PNwK/T16doYl6dR58/BqxJ\nj08C/pXqXL7/A/Sm5X3p+63p5yd59vF0YFN6Xf8v1ZXMcntNm31ZWpVhZExew0XD6BpMZIaRMSYy\nw8gYE5lhZIyJzDAyxkRmGBljIjOMjPkPubgk1CtK5QcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2ab586d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "# save the model to disk\n",
    "filename = '/Users/vgulbi/Desktop/Hackathon/programmerhumor-hackathon/public/pyscripts/Model/finalized_model.sav'\n",
    "pickle.dump(RF, open(filename, 'wb'))\n",
    " \n",
    "# # some time later...\n",
    " \n",
    "# # load the model from disk\n",
    "image = cv2.imread('/Users/vgulbi/Desktop/Hackathon/programmerhumor-hackathon/public/pyscripts/81.jpg',0)\n",
    "print(image)\n",
    "img = cv2.resize(image,(8,8))\n",
    "img = 255-img\n",
    "img = img.reshape((1,64))\n",
    "plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(img)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is procrastinating \n",
      "Who cares,  GO BACK TO WORK\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "name =  input(\"Who is procrastinating \")\n",
    "if name =='Vaida':\n",
    "    print('GO BACK TO WORK!')\n",
    "else: \n",
    "    print('Who cares, GO BACK TO WORK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
